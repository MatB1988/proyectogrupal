{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "#import missingno as msno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modificar segun entorno local\n",
    "#os.chdir( \"D:\\Estudio\\Henry Data Science\\Proyecto_N2_Grupal\\\\archivos_parquet\")\n",
    "os.chdir( \"/Volumes/hd_mvf_datasets/henry_data\")\n",
    "\n",
    "# no modificar\n",
    "folder_data = \"1_external\"\n",
    "folder_pipeline = \"2_pipelines\"\n",
    "folder_output = \"3_output\"\n",
    "folder_gmaps = \"gmaps\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pennsylvania</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          state\n",
       "0           NaN\n",
       "1    California\n",
       "2  Pennsylvania"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extraemos nombres de cada estado segun nombre de carpeta\n",
    "state_name = pd.DataFrame(\n",
    "    pd.DataFrame(\n",
    "        os.listdir(\n",
    "            os.path.join(folder_data,folder_gmaps))).rename(columns={0:\"state\"})[\"state\"].str.split(\"-\").str[1])\n",
    "state_name.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identificamos las columnas de interes y aquellas que se deben desanidar\n",
    "vars_interes=[\n",
    "    \"gmap_id\" # pk google maps\n",
    "    ,\"user_id\"\n",
    "    ,\"name\"\n",
    "    ,\"time\"\n",
    "    ,\"rating\"\n",
    "    ,\"text\"\n",
    "    #,\"pics\" # irrelevante\n",
    "    #,\"resp\" # desanidar\n",
    "    ]\n",
    "\n",
    "vars_desanidar=[\n",
    "    \"gmap_id\" # pk google maps\n",
    "    ,\"user_id\" # pk user >> resp\n",
    "    ,\"resp\" # desanidar\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(min(state_name.index),max(state_name.index)):\n",
    "\n",
    "    # creamos una variable con el nombre de estado\n",
    "    # para facilitar el loop para todos los estados\n",
    "    state = state_name[\"state\"][i]\n",
    "    folder_state = \"review-\" + str(state)\n",
    "\n",
    "    # contamos numero de archivos al interior de cada carpeta del estado\n",
    "    # para facilitar el loop\n",
    "    count_file = 0\n",
    "    # Iterate\n",
    "    for path in os.listdir(os.path.join(folder_data,folder_state)):\n",
    "        # check if current path is a file\n",
    "        if os.path.isfile(os.path.join(folder_data,folder_state,path)):\n",
    "            count_file += 1\n",
    "\n",
    "    # extraemos la informacion\n",
    "    data = []\n",
    "    for f in range(1, count_file):\n",
    "        with open(os.path.join(\n",
    "            folder_data,folder_state, str(f) + \".json\"), \"r\") as file:\n",
    "            for line in file:\n",
    "                data.append(json.loads(line))\n",
    "    gmaps_state = pd.DataFrame(data)\n",
    "\n",
    "    # nos concentramos en: vars_desanidar\n",
    "    gmaps_state_dsndr = pd.DataFrame(gmaps_state[vars_desanidar]).dropna(subset=[\"gmap_id\",\"user_id\"])\n",
    "\n",
    "    # se normaliza la columna\n",
    "    gmaps_state_dsndr = gmaps_state_dsndr.set_index([\"gmap_id\",\"user_id\"])\n",
    "    gmaps_state_dsndda = pd.json_normalize(\n",
    "        gmaps_state_dsndr[\"resp\"]).set_index(gmaps_state_dsndr.index)\n",
    "    gmaps_state_dsndda.reset_index(inplace=True) # mueve le indice a una columna\n",
    "    # renombramos para facilitar la union mas abajo\n",
    "    gmaps_state_dsndda.rename(\n",
    "        columns={\"time\":\"resp_time\",\"text\":\"resp_text\"},\n",
    "        inplace=True\n",
    "        )\n",
    "    # solo incluimos las variables de interes\n",
    "    gmaps_state_interes = gmaps_state[vars_interes].copy().dropna(subset=[\"gmap_id\",\"user_id\"])\n",
    "    # renombramos para facilitar la union mas abajo\n",
    "    gmaps_state_interes.rename(\n",
    "        columns={\"name\":\"user_name\",\"time\":\"user_time\",\"text\":\"user_text\"},\n",
    "        inplace=True\n",
    "        )\n",
    "\n",
    "    # unir los dataframes\n",
    "    gmaps_state_norm = pd.merge(\n",
    "        gmaps_state_interes,\n",
    "        gmaps_state_dsndda,\n",
    "        on=[\"gmap_id\",\"user_id\"],\n",
    "        how=\"left\")\n",
    "\n",
    "    # generamos una columna state\n",
    "    # para facilitar la union de todos los datos\n",
    "    gmaps_state_norm[\"state\"] = state\n",
    "\n",
    "    # movemos 'state' a la primera fila para facilitar la visualizacion\n",
    "    first_column = gmaps_state_norm.pop(\"state\")\n",
    "    gmaps_state_norm.insert(0, \"state\", first_column)\n",
    "    \n",
    "    # Convierte la columna 'user_time' a datetime y almacena el resultado en una nueva columna 'time_total'\n",
    "    gmaps_state_norm['user_time_total'] = pd.to_datetime(gmaps_state_norm['user_time'], unit='ms',errors='coerce')\n",
    "    gmaps_state_norm['user_time_year'] = gmaps_state_norm['time_total'].dt.year\n",
    "    gmaps_state_norm['user_time_month'] = gmaps_state_norm['time_total'].dt.month\n",
    "    gmaps_state_norm['user_time_day'] = gmaps_state_norm['time_total'].dt.day\n",
    "    gmaps_state_norm['user_time_hour'] = gmaps_state_norm['time_total'].dt.hour\n",
    "    gmaps_state_norm['resp_time'] = pd.to_datetime(gmaps_state_norm['resp_time'], errors='coerce')\n",
    "\n",
    "    # Convierte todo el texto a min√∫sculas\n",
    "    gmaps_state_norm['user_text'] = gmaps_state_norm['user_text'].str.lower()\n",
    "    \n",
    "    #Calcula la longitud del texto\n",
    "    gmaps_state_norm['user_text_length'] = gmaps_state_norm['user_text'].str.len()\n",
    "    \n",
    "    # Quita duplicados\n",
    "    gmaps_state_norm.drop_duplicates(inplace=True)\n",
    "\n",
    "    # df final por estado\n",
    "    # guardamos en pipeline con el fin de alivianar la carga al RAM local\n",
    "    gmaps_state_norm.to_parquet(\n",
    "        os.path.join(folder_pipeline, str(folder_state) + \"_norm.parquet\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
