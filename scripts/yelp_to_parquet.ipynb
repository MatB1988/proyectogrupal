{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este etl tiene como objetivo poder disponer de toda la informacion recibida de Yelp en formato parquet para ser procesada con pandas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import json\n",
    "import os\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import fastparquet as fp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el repositorio local, este archivo yelp_to_parquet.ipynb, toma los datos del dataset consigna de una carpeta llamada yelp, en la que se encuentran los archivos:\n",
    "business.pkl\n",
    "checkin.json\n",
    "review.json\n",
    "tip.json\n",
    "user.parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "business.pkl to parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta a la carpeta Yelp\n",
    "yelp_folder = 'yelp'\n",
    "\n",
    "file_to_df = 'business.pkl'\n",
    "\n",
    "# Leer el archivo business.pkl\n",
    "df_business = pd.read_pickle(os.path.join(yelp_folder, file_to_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_df = df_business.iloc[:, :14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar si el directorio 'parquet' existe, y si no, crearlo\n",
    "if not os.path.exists('parquet'):\n",
    "    os.makedirs('parquet')\n",
    "\n",
    "# Obtener el nombre del archivo original sin la extensión\n",
    "df_2_file_name = 'business.pkl'.split('.')[0]\n",
    "\n",
    "# Guardar el DataFrame en formato Parquet en el directorio 'parquet' con el nombre del archivo original\n",
    "file_path = os.path.join('parquet', f'{df_2_file_name}.parquet')\n",
    "\n",
    "# Guardar el DataFrame en formato Parquet usando fastparquet\n",
    "business_df.to_parquet(file_path, engine='fastparquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "checkin.json to parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta al archivo checkin.json dentro de la carpeta Yelp\n",
    "checkin_path = os.path.join('yelp', 'checkin.json')\n",
    "\n",
    "# Lista para almacenar los DataFrames\n",
    "checkin_dfs = []\n",
    "\n",
    "# Leer el archivo línea por línea y convertir cada línea en un DataFrame\n",
    "with open(checkin_path, 'r') as checkin_file:\n",
    "    for line in checkin_file:\n",
    "        data = eval(line)  # Convertir la línea en un diccionario\n",
    "        df = pd.DataFrame([data])  # Crear un DataFrame a partir del diccionario\n",
    "        checkin_dfs.append(df)\n",
    "\n",
    "# Concatenar los DataFrames en uno solo\n",
    "checkin_df = pd.concat(checkin_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar si el directorio 'parquet' existe, y si no, crearlo\n",
    "if not os.path.exists('parquet'):\n",
    "    os.makedirs('parquet')\n",
    "\n",
    "# Obtener el nombre del archivo original sin la extensión\n",
    "df_2_file_name = 'checkin.json'.split('.')[0]\n",
    "\n",
    "# Guardar el DataFrame en formato Parquet en el directorio 'parquet' con el nombre del archivo original\n",
    "file_path = os.path.join('parquet', f'{df_2_file_name}.parquet')\n",
    "\n",
    "# A continuación, se guarda el DataFrame en formato Parquet usando fastparquet\n",
    "checkin_df.to_parquet(file_path, engine='fastparquet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tip.json to parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta al archivo tip.json dentro de la carpeta Yelp\n",
    "tip_path = os.path.join('yelp', 'tip.json')\n",
    "\n",
    "# Lista para almacenar los DataFrames\n",
    "tip_df = []\n",
    "\n",
    "# Leer el archivo línea por línea y convertir cada línea en un DataFrame\n",
    "with open(tip_path, 'r', encoding='utf-8') as tip_file:\n",
    "    for line in tip_file:\n",
    "        data = json.loads(line)  # Convertir la línea en un diccionario\n",
    "        df = pd.DataFrame([data])  # Crear un DataFrame a partir del diccionario\n",
    "        tip_df.append(df)\n",
    "\n",
    "# Concatenar los DataFrames en uno solo\n",
    "tip_df = pd.concat(tip_df, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformar columna 'date' a formato datetime\n",
    "tip_df['date'] = pd.to_datetime(tip_df['date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame guardado como parquet\\tip.parquet\n"
     ]
    }
   ],
   "source": [
    "# Verificar si el directorio 'parquet' existe, y si no, crearlo\n",
    "if not os.path.exists('parquet'):\n",
    "    os.makedirs('parquet')\n",
    "\n",
    "# Obtener el nombre del archivo original sin la extensión\n",
    "df_2_file_name = 'tip.json'.split('.')[0]\n",
    "\n",
    "# Guardar el DataFrame en formato Parquet en el directorio 'parquet' con el nombre del archivo original\n",
    "file_path = os.path.join('parquet', f'{df_2_file_name}.parquet')\n",
    "\n",
    "# A continuación, se guarda el DataFrame en formato Parquet usando fastparquet\n",
    "tip_df.to_parquet(file_path, engine='fastparquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "review.json to pq_review(parquet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta del archivo original y copia\n",
    "archivo_original = 'Yelp/review.json'\n",
    "archivo_copia = 'Yelp/review_copia.json'\n",
    "\n",
    "# Copiar el archivo original a review_copia.json\n",
    "with open(archivo_original, 'r', encoding='utf-8') as original_file:\n",
    "    data = [json.loads(line) for line in original_file]\n",
    "    with open(archivo_copia, 'w', encoding='utf-8') as copia_file:\n",
    "        for line in data:\n",
    "            json.dump(line, copia_file)\n",
    "            copia_file.write('\\n')\n",
    "\n",
    "# Número de líneas por archivo parquet\n",
    "lineas_por_archivo = 1000000\n",
    "numero_archivo = 1\n",
    "linea_actual = 0\n",
    "df_actual = []\n",
    "lista_df_reviews = []  # Lista para almacenar DataFrames\n",
    "\n",
    "# Crear la carpeta para guardar los archivos parquet\n",
    "if not os.path.exists('pq_review'):\n",
    "    os.makedirs('pq_review')\n",
    "\n",
    "for linea in data:\n",
    "    df_actual.append(linea)\n",
    "    linea_actual += 1\n",
    "\n",
    "    if linea_actual == lineas_por_archivo:\n",
    "        # Crear un DataFrame\n",
    "        df = pd.DataFrame(df_actual)\n",
    "        \n",
    "        # Agregar el DataFrame a la lista\n",
    "        lista_df_reviews.append(df)\n",
    "\n",
    "        # Nombre del archivo parquet\n",
    "        nombre_archivo = f'pq_review/review_{str(numero_archivo).zfill(2)}.parquet'\n",
    "\n",
    "        # Guardar el DataFrame como archivo parquet\n",
    "        df.to_parquet(nombre_archivo, index=False)\n",
    "\n",
    "        # Reiniciar el contador de líneas y el DataFrame actual\n",
    "        linea_actual = 0\n",
    "        df_actual = []\n",
    "        numero_archivo += 1\n",
    "\n",
    "# Si quedan líneas en el último DataFrame\n",
    "if df_actual:\n",
    "    df = pd.DataFrame(df_actual)\n",
    "    \n",
    "    # Agregar el último DataFrame a la lista\n",
    "    lista_df_reviews.append(df)\n",
    "    \n",
    "    nombre_archivo = f'pq_review/review_{str(numero_archivo).zfill(2)}.parquet'\n",
    "    df.to_parquet(nombre_archivo, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lista_df_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta del archivo original\n",
    "archivo_original = 'yelp/review.json'\n",
    "\n",
    "# Número de líneas por archivo parquet\n",
    "lineas_por_archivo = 1000000\n",
    "numero_archivo = 1\n",
    "linea_actual = 0\n",
    "df_actual = []\n",
    "lista_df_reviews = []  # Lista para almacenar DataFrames\n",
    "\n",
    "# Crear el directorio parquet y pq_review si no existen\n",
    "if not os.path.exists('parquet/pq_review'):\n",
    "    os.makedirs('parquet/pq_review')\n",
    "\n",
    "# Leer el archivo original y escribir archivos Parquet\n",
    "with open(archivo_original, 'r', encoding='utf-8') as original_file:\n",
    "    for line in original_file:\n",
    "        # Cargar la línea como un objeto JSON\n",
    "        linea = json.loads(line)\n",
    "        \n",
    "        # Agregar la línea al DataFrame actual\n",
    "        df_actual.append(linea)\n",
    "        linea_actual += 1\n",
    "\n",
    "        # Si se alcanza el número de líneas por archivo parquet\n",
    "        if linea_actual == lineas_por_archivo:\n",
    "            # Crear un DataFrame\n",
    "            df = pd.DataFrame(df_actual)\n",
    "        \n",
    "            # Agregar el DataFrame a la lista\n",
    "            lista_df_reviews.append(df)\n",
    "\n",
    "            # Nombre del archivo parquet\n",
    "            nombre_archivo = f'parquet/pq_review/review_{str(numero_archivo).zfill(2)}.parquet'\n",
    "\n",
    "            # Guardar el DataFrame como archivo parquet\n",
    "            df.to_parquet(nombre_archivo, index=False)\n",
    "\n",
    "            # Reiniciar el contador de líneas y el DataFrame actual\n",
    "            linea_actual = 0\n",
    "            df_actual = []\n",
    "            numero_archivo += 1\n",
    "\n",
    "# Si quedan líneas en el último DataFrame\n",
    "if df_actual:\n",
    "    df = pd.DataFrame(df_actual)\n",
    "    \n",
    "    # Agregar el último DataFrame a la lista\n",
    "    lista_df_reviews.append(df)\n",
    "    \n",
    "    nombre_archivo = f'parquet/pq_review/review_{str(numero_archivo).zfill(2)}.parquet'\n",
    "    df.to_parquet(nombre_archivo, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "user.parquet to pq_user(parquet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proceso completado.\n"
     ]
    }
   ],
   "source": [
    "# Ruta al archivo Parquet original\n",
    "input_parquet_file = 'yelp/user.parquet'\n",
    "\n",
    "# Directorio para guardar los archivos Parquet resultantes\n",
    "output_dir = 'parquet/pq_user'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Tamaño del lote (número de filas por archivo Parquet)\n",
    "batch_size = 1000000\n",
    "\n",
    "# Inicializamos un contador para el nombre de archivo\n",
    "file_counter = 1\n",
    "\n",
    "while True:\n",
    "    # Lee un lote del archivo Parquet original\n",
    "    start_row = (file_counter - 1) * batch_size\n",
    "    end_row = start_row + batch_size\n",
    "    user_table = pq.read_table(input_parquet_file, columns=None, use_threads=False)\n",
    "    user_df = user_table.to_pandas()\n",
    "    user_df = user_df.iloc[start_row:end_row]\n",
    "    \n",
    "    # Verifica si se han leído todas las filas\n",
    "    if user_df.empty:\n",
    "        break\n",
    "    \n",
    "    # Genera el nombre del archivo Parquet\n",
    "    output_file = os.path.join(output_dir, f'user_{file_counter:02d}.parquet')\n",
    "    \n",
    "    # Guarda el lote actual en un archivo Parquet\n",
    "    table = pa.Table.from_pandas(user_df)\n",
    "    pq.write_table(table, output_file)\n",
    "    \n",
    "    # Incrementa el contador de archivos\n",
    "    file_counter += 1\n",
    "\n",
    "print(\"Proceso completado.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvYelp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
